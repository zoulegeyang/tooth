{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\揍了个羊\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\揍了个羊\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\揍了个羊\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\揍了个羊\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\揍了个羊\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\揍了个羊\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\aaa.jpg\n",
      "[[  0   1   0 ...   1   0   0]\n",
      " [  0   0   7 ...  10   0   0]\n",
      " [  0   2 227 ...  75   3   0]\n",
      " ...\n",
      " [  0   5 214 ... 229  38   0]\n",
      " [  0   1  27 ...  77   1   0]\n",
      " [  0   0   2 ...   3   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\aaaaa.jpg\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   2 105 ... 118   4   0]\n",
      " ...\n",
      " [  0   9  34 ... 221   1   0]\n",
      " [  0   0   0 ...   6   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\axx.jpg\n",
      "[[  0   0   1 ...   0   0   0]\n",
      " [  0   0   9 ...   0   0   0]\n",
      " [  0   1  83 ...   0   0   0]\n",
      " ...\n",
      " [  0  21 200 ... 145  15   0]\n",
      " [  0   0  54 ...  40   1   0]\n",
      " [  0   0   0 ...   3   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\cc.jpg\n",
      "[[  0   0   5 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   1 154 ...  91   0   0]\n",
      " ...\n",
      " [  0   0  33 ... 227   1   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   5 ...   6   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\hh.jpg\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   2 174 ...   0   0   0]\n",
      " ...\n",
      " [  0   9 156 ...   3   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\hhhhhhhh.jpg\n",
      "[[  0   0   1 ...   3   0   1]\n",
      " [  0   0   7 ...  14   1   0]\n",
      " [  0   1 206 ... 148   7   1]\n",
      " ...\n",
      " [  0  14 160 ... 234  33   1]\n",
      " [  0   1  34 ...  77   0   0]\n",
      " [  0   1   1 ...   3   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\jjj.jpg\n",
      "[[  0   0   1 ...   2   0   0]\n",
      " [  0   0  13 ...   9   0   1]\n",
      " [  0   0 213 ...  92   4   2]\n",
      " ...\n",
      " [  0  13 180 ...   0   0   0]\n",
      " [  0   1  47 ...   0   0   0]\n",
      " [  0   0   1 ...   0   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\sssssssss.jpg\n",
      "[[  0   1   0 ...   1   0   0]\n",
      " [  0   0   7 ...  10   0   0]\n",
      " [  0   2 227 ...  75   3   0]\n",
      " ...\n",
      " [  0   5 214 ... 229  38   0]\n",
      " [  0   1  27 ...  77   1   0]\n",
      " [  0   0   2 ...   3   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\xxxx.jpg\n",
      "[[  1   0   0 ...   2   0   0]\n",
      " [  0   0   8 ...  21   0   0]\n",
      " [  0   3 239 ... 226  10   1]\n",
      " ...\n",
      " [  0  13 146 ...  31   5   0]\n",
      " [  0   0  35 ...  16   1   0]\n",
      " [  0   0   1 ...   2   0   0]]\n",
      "D:\\QQdowanload\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\3\\xxxxxx.jpg\n",
      "[[  0   0   2 ...   0   0   0]\n",
      " [  0   1   9 ...   0   0   0]\n",
      " [  1   1 184 ...   0   0   0]\n",
      " ...\n",
      " [  0  10 159 ...  97  15   1]\n",
      " [  0   1  39 ...  34   1   0]\n",
      " [  0   0   1 ...   5   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opencV代码块\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir_mstar = 'D:\\\\QQdowanload\\\\2019-06-21 00-00-00-2019-08-20 12-00-00yuanpian\\data\\\\3'\n",
    "\n",
    "filenames = os.listdir(dir_mstar)\n",
    "filelist = [os.path.join(dir_mstar, file) for file in filenames]\n",
    "images2=[]\n",
    "labels=[]\n",
    "i=0\n",
    "for file in filelist:\n",
    "    \n",
    "    aa=cv2.imread(file,0) \n",
    "    print(file)\n",
    "    \n",
    "    bb=cv2.resize(aa, (40, 40))\n",
    "#     cv2.imshow('bb',bb)\n",
    "    print(bb)#显示缩放后的图片\n",
    "       \n",
    "#     cv2.waitKey(0) \n",
    "    \n",
    "    images2.append(bb)\n",
    "    i+=1\n",
    "cc=np.array(images2,dtype='float')\n",
    "#做个假数据 i是代表图片总量，10是假设有5个点，每个点有两个数据即x,y坐标\n",
    "labels=np.random.rand(i,20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 40, 40, 1) (7, 20)\n"
     ]
    }
   ],
   "source": [
    "#s数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "cc=cc.reshape(-1,40,40,1)\n",
    "#该处由于没有labels所以就没有进行处理\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(cc, labels, test_size = 0.3)\n",
    "\n",
    "\n",
    "# train_images, test_images= train_test_split(cc,test_size = 0.3)\n",
    "print(train_images.shape,train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,Activation,Input,Dot,multiply,ZeroPadding2D,Lambda,Reshape,concatenate,add,Flatten\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 40, 40, 16)\n",
      "Train on 7 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 250.3668 - acc: 0.0000e+00 - val_loss: 30.3969 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 142.1693 - acc: 0.1429 - val_loss: 25.6392 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 118.1142 - acc: 0.0000e+00 - val_loss: 13.0793 - val_acc: 0.3333\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 102.6851 - acc: 0.0000e+00 - val_loss: 9.9229 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 73.4536 - acc: 0.1429 - val_loss: 8.5941 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 70.3707 - acc: 0.2857 - val_loss: 9.6663 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 51.1769 - acc: 0.1429 - val_loss: 6.9865 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 60.0608 - acc: 0.0000e+00 - val_loss: 4.4310 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 43.7242 - acc: 0.0000e+00 - val_loss: 3.5370 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 32.7347 - acc: 0.0000e+00 - val_loss: 3.5252 - val_acc: 0.3333\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 33.2913 - acc: 0.2857 - val_loss: 2.4753 - val_acc: 0.3333\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 25.0130 - acc: 0.1429 - val_loss: 2.3779 - val_acc: 0.3333\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 27.1643 - acc: 0.0000e+00 - val_loss: 2.0807 - val_acc: 0.3333\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 14.9349 - acc: 0.0000e+00 - val_loss: 2.0718 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 18.7668 - acc: 0.0000e+00 - val_loss: 1.8087 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 12.4361 - acc: 0.0000e+00 - val_loss: 1.7595 - val_acc: 0.3333\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 13.7890 - acc: 0.0000e+00 - val_loss: 1.4891 - val_acc: 0.3333\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 12.4457 - acc: 0.0000e+00 - val_loss: 1.3809 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.8395 - acc: 0.0000e+00 - val_loss: 1.3426 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 8.7294 - acc: 0.1429 - val_loss: 1.3372 - val_acc: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.7947719 , -0.36156413,  0.976563  ,  0.67706275, -0.15412629,\n",
       "         0.88245547,  1.1958103 ,  0.04300353,  2.3753204 , -0.3438616 ,\n",
       "         0.22246844,  0.9156539 ,  1.086321  ,  0.14316715,  0.08543287,\n",
       "        -0.7641645 ,  2.189305  ,  1.0241998 ,  1.6980493 ,  0.827852  ],\n",
       "       [ 0.5700859 , -0.5478462 ,  0.41613233, -1.1607072 ,  0.5267634 ,\n",
       "         0.88771874,  1.4835494 , -0.439979  ,  1.0491705 ,  0.2622538 ,\n",
       "         2.1750531 ,  0.6856421 , -0.48828715,  1.0190716 , -0.513712  ,\n",
       "        -0.3786249 ,  1.545218  ,  0.41358706,  1.4206338 ,  1.675293  ],\n",
       "       [-1.719356  ,  1.1261644 , -0.42821714,  0.9451484 , -0.4245649 ,\n",
       "         2.949914  ,  3.2951648 , -1.4118975 ,  3.7268736 , -1.4287617 ,\n",
       "        -0.4819728 ,  1.4659694 , -1.0214217 ,  1.0530499 ,  0.41042724,\n",
       "         0.41054493,  0.41183084,  0.25613615,  3.5806243 , -0.4121939 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#做回归的到点的坐标\n",
    "inputs=Input(shape=(40,40,1))\n",
    "x=Conv2D(16,(3,3),padding='same')(inputs)\n",
    "print(x.shape)\n",
    "x=Activation('relu')(x)\n",
    "x=Conv2D(32,(3,3),padding='same')(x)\n",
    "x=Activation('relu')(x)\n",
    "x=MaxPooling2D((2,2))(x)\n",
    "x=Dropout(0.25)(x)\n",
    "x=Conv2D(64,(3,3),padding='same')(x)\n",
    "x=Activation('relu')(x)\n",
    "x=Conv2D(64,(3,3),padding='same')(x)\n",
    "x=Activation('relu')(x)\n",
    "x=MaxPooling2D(2,2)(x)\n",
    "x=Dropout(0.25)(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(52)(x)\n",
    "predictions=Dense(20)(x)\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model=Model(inputs=inputs,outputs=predictions)\n",
    "model.compile(optimizer=opt,loss='mse',metrics=['acc'])\n",
    "y=model.fit(train_images,train_labels,batch_size=1,\n",
    "              epochs=20,\n",
    "              validation_data=(test_images, test_labels),\n",
    "              shuffle=True)\n",
    "Y_pred=model.predict(test_images)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1., 1., 1., 2., 1., 1., 1., 1.],\n",
       "       [2., 1., 2., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 2., 1., 2., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 2., 1., 2., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 2., 1., 2., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 2., 1., 2., 1., 1., 1.],\n",
       "       [2., 1., 1., 1., 1., 2., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 2., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 2., 1., 2.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 2., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#做一个点的邻接矩阵 即边的关系 定义为若两个点之间有边 则为1 否则为0\n",
    "import numpy as np\n",
    "# 定义边关系\n",
    "edges = np.array([[1, 2], [1, 6], [2, 1], [2, 3], [3, 2], [3, 4], [4,\n",
    "                                                                   3], [4, 5],\n",
    "                  [5, 4], [5, 6], [6, 5], [6, 7], [7, 6], [7, 1], [8, 9],\n",
    "                  [9, 8], [9, 10], [10, 9]])\n",
    "edges = edges - 1\n",
    "# 做邻接矩阵\n",
    "adj = np.ones(shape=(10, 10))\n",
    "\n",
    "for i in edges:\n",
    "    adj[i[0]][[i[1]]] = 2\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = Y_pred\n",
    "# 定义隐状态结点向量\n",
    "hidden = np.random.random((3,10, 4))\n",
    "n1=n1.reshape([-1, 10, 2])\n",
    "n1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方案1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用公式如下:adj 附近结点：fnodes全部相加/3 nodes+fnodes-->10,2 =nf adj diancheng nf-->10,2 =adjnf (adjnf+hidden)/2-->10,2 在flatten之后得20,1 后进行一维卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该方法并没有定义中间权值所以无需定义中间层 只需要对输入进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.7947719  -0.36156413]\n",
      "   [-0.15412629  0.88245547]]\n",
      "\n",
      "  [[ 0.976563    0.67706275]\n",
      "   [ 1.1958103   0.04300353]]\n",
      "\n",
      "  [[-0.15412629  0.88245547]\n",
      "   [ 2.3753204  -0.3438616 ]]\n",
      "\n",
      "  [[ 1.1958103   0.04300353]\n",
      "   [ 0.22246844  0.9156539 ]]\n",
      "\n",
      "  [[ 2.3753204  -0.3438616 ]\n",
      "   [ 1.086321    0.14316715]]\n",
      "\n",
      "  [[ 0.22246844  0.9156539 ]\n",
      "   [-0.7947719  -0.36156413]]\n",
      "\n",
      "  [[ 2.189305    1.0241998 ]\n",
      "   [ 0.08543287 -0.7641645 ]]\n",
      "\n",
      "  [[ 0.08543287 -0.7641645 ]\n",
      "   [ 1.6980493   0.827852  ]]\n",
      "\n",
      "  [[ 2.189305    1.0241998 ]\n",
      "   [ 0.08543287 -0.7641645 ]]\n",
      "\n",
      "  [[ 0.976563    0.67706275]\n",
      "   [ 0.22246844  0.9156539 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.5700859  -0.5478462 ]\n",
      "   [ 0.5267634   0.88771874]]\n",
      "\n",
      "  [[ 0.41613233 -1.1607072 ]\n",
      "   [ 1.4835494  -0.439979  ]]\n",
      "\n",
      "  [[ 0.5267634   0.88771874]\n",
      "   [ 1.0491705   0.2622538 ]]\n",
      "\n",
      "  [[ 1.4835494  -0.439979  ]\n",
      "   [ 2.1750531   0.6856421 ]]\n",
      "\n",
      "  [[ 1.0491705   0.2622538 ]\n",
      "   [-0.48828715  1.0190716 ]]\n",
      "\n",
      "  [[ 2.1750531   0.6856421 ]\n",
      "   [ 0.5700859  -0.5478462 ]]\n",
      "\n",
      "  [[ 1.545218    0.41358706]\n",
      "   [-0.513712   -0.3786249 ]]\n",
      "\n",
      "  [[-0.513712   -0.3786249 ]\n",
      "   [ 1.4206338   1.675293  ]]\n",
      "\n",
      "  [[ 1.545218    0.41358706]\n",
      "   [-0.513712   -0.3786249 ]]\n",
      "\n",
      "  [[ 0.41613233 -1.1607072 ]\n",
      "   [ 2.1750531   0.6856421 ]]]\n",
      "\n",
      "\n",
      " [[[-1.719356    1.1261644 ]\n",
      "   [-0.4245649   2.949914  ]]\n",
      "\n",
      "  [[-0.42821714  0.9451484 ]\n",
      "   [ 3.2951648  -1.4118975 ]]\n",
      "\n",
      "  [[-0.4245649   2.949914  ]\n",
      "   [ 3.7268736  -1.4287617 ]]\n",
      "\n",
      "  [[ 3.2951648  -1.4118975 ]\n",
      "   [-0.4819728   1.4659694 ]]\n",
      "\n",
      "  [[ 3.7268736  -1.4287617 ]\n",
      "   [-1.0214217   1.0530499 ]]\n",
      "\n",
      "  [[-0.4819728   1.4659694 ]\n",
      "   [-1.719356    1.1261644 ]]\n",
      "\n",
      "  [[ 0.41183084  0.25613615]\n",
      "   [ 0.41042724  0.41054493]]\n",
      "\n",
      "  [[ 0.41042724  0.41054493]\n",
      "   [ 3.5806243  -0.4121939 ]]\n",
      "\n",
      "  [[ 0.41183084  0.25613615]\n",
      "   [ 0.41042724  0.41054493]]\n",
      "\n",
      "  [[-0.42821714  0.9451484 ]\n",
      "   [-0.4819728   1.4659694 ]]]]\n",
      "(3, 10, 2) (3, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "# def concat(n1,h1):\n",
    "#     #先找所有n1的附近的点\n",
    "# for\n",
    "# zhao每个点的邻近结点\n",
    "s = []\n",
    "b = []\n",
    "c = []\n",
    "for each in n1:\n",
    "   \n",
    "    for i, eeach in enumerate(each):\n",
    "        if i == 0:\n",
    "            s.append(each[1])\n",
    "            #             print(each[1])\n",
    "            s.append(each[5])\n",
    "\n",
    "            z0 = np.array(s)\n",
    "            s = []\n",
    "\n",
    "        if i == 1:\n",
    "            s.append(each[0])\n",
    "            #             print(each[1])\n",
    "            s.append(each[2])\n",
    "            z1 = np.array(s)\n",
    "            s = []\n",
    "        if i == 2:\n",
    "            s.append(each[1])\n",
    "            s.append(each[3])\n",
    "            z2 = np.array(s)\n",
    "            s = []\n",
    "        if i == 3:\n",
    "            s.append(each[2])\n",
    "            s.append(each[4])\n",
    "            z3 = np.array(s)\n",
    "            s = []\n",
    "        if i == 4:\n",
    "            s.append(each[3])\n",
    "            s.append(each[5])\n",
    "            z4 = np.array(s)\n",
    "            s = []\n",
    "        if i == 5:\n",
    "            s.append(each[4])\n",
    "            s.append(each[6])\n",
    "            z5 = np.array(s)\n",
    "            s = []\n",
    "        if i == 6:\n",
    "            s.append(each[5])\n",
    "            s.append(each[0])\n",
    "            z6 = np.array(s)\n",
    "            s = []\n",
    "        if i == 7:\n",
    "            s.append(each[8])\n",
    "\n",
    "            s.append(each[7])\n",
    "            z7 = np.array(s)\n",
    "            s = []\n",
    "        if i == 8:\n",
    "            s.append(each[7])\n",
    "            s.append(each[9])\n",
    "            z8 = np.array(s)\n",
    "            s = []\n",
    "        if i == 9:\n",
    "            s.append(each[8])\n",
    "            s.append(each[7])\n",
    "            z9 = np.array(s)\n",
    "            s = []\n",
    "\n",
    "    b.append(z1)\n",
    "    b.append(z2)\n",
    "    b.append(z3)\n",
    "    b.append(z4)\n",
    "    b.append(z5)\n",
    "    b.append(z6)\n",
    "    b.append(z7)\n",
    "    b.append(z8)\n",
    "    b.append(z9)\n",
    "    b.append(z0)\n",
    "    c.append(b)\n",
    "    b = []\n",
    "c = np.array(c)\n",
    "c.shape\n",
    "print(c)\n",
    "# 分别为batch 结点index 边数对应的结点index 维度\n",
    "for each in c:\n",
    "        for e in each:\n",
    "            e[0]=(e[0]+e[-1])/2\n",
    "                \n",
    "c=c[:,:,0]\n",
    "#得到附近结点的和向量\n",
    "print(c.shape,n1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将fondes和node连接在一起 作为图卷积的输入\n",
    "nz=np.concatenate((c,n1),axis=2)\n",
    "nz.shape\n",
    "nz=np.add(nz,hidden)\n",
    "nz.shape\n",
    "\n",
    "nz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a=np.random.random((3,10,2,2))\n",
    "# print(a)\n",
    "# for i in a:\n",
    "#     for e in i:\n",
    "#         e[0]=(e[0]+e[-1])/2\n",
    "# a=a[:,:,0]\n",
    "# type(a)\n",
    "# 测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 编写自己的层 定义一个权值矩阵作为图卷积优化的一部分\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "# class MyLayer(Layer):\n",
    "#     def __init__(self,**kwargs):\n",
    "# #         self.output_dim = output_dim\n",
    "# #         if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "# #             kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "#         super(MyLayer, self).__init__(**kwargs)\n",
    "        \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.W = self.add_weight(shape=(input_shape[-1], 10),\n",
    "#                                 initializer='random_uniform',name='hao',\n",
    "#                                 trainable=True)\n",
    "#         super(MyLayer, self).build()  # be sure you call this somewhere! \n",
    "\n",
    "#     def call(self, x, mask=None):\n",
    "#         a=K.dot(x,self.W)\n",
    "#         return K.dot(a,adj)\n",
    "            \n",
    "\n",
    "#     def get_output_shape_for(self, input_shape):\n",
    "#         return tuple(input_shape[0] ,10)\n",
    "\n",
    "class MyLayer(Layer):\n",
    " \n",
    "    def __init__(self, output_dim,adj, **kwargs):\n",
    "        self.adj=adj\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        # 为该层创建一个可训练的权重\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[-1], self.adj.shape[0]),\n",
    "                                      initializer='uniform',\n",
    "                                      \n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # 一定要在最后调用它\n",
    " \n",
    "    def call(self, x):\n",
    "        a=K.dot(x,self.kernel)\n",
    "        adj=K.constant(self.adj)\n",
    "        print(adj)\n",
    "        return K.dot(a,adj)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], adj.shape[-1])\n",
    "\n",
    "\n",
    "\n",
    "# class MyLayer2(Layer):\n",
    "\n",
    "#     def __init__(self, output_dim, adj,**kwargs):\n",
    "#         self.output_dim = output_dim\n",
    "#         self.adj=adj\n",
    "#         super(MyLayer2, self).__init__(**kwargs)\n",
    "    \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         # Create a trainable weight variable for this layer.\n",
    "#         self.kernel = self.add_weight(name='kernel', \n",
    "#                                       shape=(input_shape[-1], self.output_dim),\n",
    "#                                       initializer='uniform',\n",
    "#                                       trainable=True)\n",
    "        \n",
    "#         super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "#     def call(self, x):\n",
    "        \n",
    "#         a=K.dot(x,self.kernel)\n",
    "#         print(1)\n",
    "        \n",
    "# #         adj=K.variable(self.adj)\n",
    "# #         print(2)\n",
    "# #         return K.dot(a,adj)\n",
    "        \n",
    "        \n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], self.output_dim)\n",
    "\n",
    "mylayer=MyLayer(10,adj)\n",
    "print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"my_layer_2_8/Const:0\", shape=(10, 10), dtype=float32)\n",
      "(?, 10, 10)\n",
      "(?, 10, 10)\n",
      "(?, 10, 10, 1)\n",
      "(?, 4, 1, 10) 2\n",
      "3\n",
      "(?, 10, 4)\n",
      "1\n",
      "Tensor(\"my_layer_2_9/Const:0\", shape=(10, 10), dtype=float32)\n",
      "(?, 10, 10)\n",
      "(?, 10, 10)\n",
      "(?, 10, 10, 1)\n",
      "(?, 4, 1, 10)\n",
      "(?, 10, 4)\n",
      "(?, ?)\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 5.0189 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.6072 - acc: 0.3333\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.7645 - acc: 0.3333\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9122 - acc: 0.6667\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3162 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1156 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 989us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 989us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.9836e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.6910e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.4142e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9.1505e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.9002e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.6617e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.4340e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.2177e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.0103e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.8123e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.6228e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.4412e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.2675e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.1006e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.9410e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.7875e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.6398e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.4976e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.3608e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.2294e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.1024e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.9803e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.8626e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.7487e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.6388e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.5326e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.4301e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.3305e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.2347e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.1414e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.0516e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.9641e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.8798e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.7981e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.7182e-04 - acc: 1.0000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 4.6407e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.5660e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.4930e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.4223e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.3533e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.2863e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.2217e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.1583e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.0965e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.0364e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9780e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9210e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.8657e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.8111e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.7586e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.7071e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.6568e-04 - acc: 1.0000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 10, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "my_layer_2 (MyLayer)            (None, 10)           40          input_10[0][0]                   \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 10, 1)        0           my_layer_2[8][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 12, 1)        0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 10)        310         zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 10, 4)        0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 10, 4)        0           reshape_13[0][0]                 \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 10, 1)        0           my_layer_2[9][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 12, 1)        0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 10)        310         zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 10, 4)        0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 10, 4)        0           reshape_14[0][0]                 \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 40)           0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 4)            164         flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4)            20          dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 844\n",
      "Trainable params: 844\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# class MyLayer2(Layer):\n",
    "\n",
    "#     def __init__(self,**kwargs):\n",
    "#          super(MyLayer2, self).__init__(**kwargs)\n",
    "        \n",
    "\n",
    "# #     def build(self, input_shape):\n",
    "# #         # Create a trainable weight variable for this layer.\n",
    "# #         self.kernel = self.add_weight(name='kernel', \n",
    "# #                                       shape=(input_shape[-1], self.output_dim),\n",
    "# #                                       initializer='uniform',\n",
    "# #                                       trainable=True)\n",
    "        \n",
    "# #         super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "#     def call(self, x,y):\n",
    "        \n",
    "# #         a=K.dot(x,self.kernel)\n",
    "# #         print(1)\n",
    "        \n",
    "# #         adj=K.variable(self.adj)\n",
    "# #         print(2)\n",
    "#         return K.dot(x,y)\n",
    "        \n",
    "        \n",
    "\n",
    "#     def compute_output_shape(self):\n",
    "#         return (x.shape[0], y.shape[1])\n",
    "\n",
    "\n",
    "# print(x.shape)\n",
    "def res(x):\n",
    "#     print(type(x))\n",
    "    x=K.expand_dims(x,axis=-1)\n",
    "#     print(x.shape)\n",
    "    return x\n",
    "inputs=Input(shape=(10,4))\n",
    "x=mylayer(inputs)\n",
    "print(x.shape)\n",
    "print(x.shape)\n",
    "x=Lambda(res)(x)\n",
    "print(x.shape)\n",
    "x=ZeroPadding2D(padding=((1,1),(0,0)))(x)\n",
    "x.shape\n",
    "x=Conv2D(10,(3,10),strides=3,padding='valid')(x)\n",
    "print(x.shape,2)\n",
    "# 得到10个结点的隐状态向量\n",
    "x=Reshape((10,4))(x)\n",
    "print(3)\n",
    "print(x.shape)\n",
    "print(1)\n",
    "x=add([x,inputs])\n",
    "# def re(x):\n",
    "#     x=K.reshape(x,(None,-1))\n",
    "#     return x\n",
    "def graphconv(z,inputs):\n",
    "    z=mylayer(z)\n",
    "    print(z.shape)\n",
    "    print(z.shape)\n",
    "    z=Lambda(res)(z)\n",
    "    print(z.shape)\n",
    "    z=ZeroPadding2D(padding=((1,1),(0,0)))(z)\n",
    "    \n",
    "    z=Conv2D(10,(3,10),strides=3,padding='valid')(z)\n",
    "    print(z.shape)\n",
    "    # 得到10个结点的隐状态向量\n",
    "    z=Reshape((10,4))(z)\n",
    "    z.shape\n",
    "    z=add([z,inputs])\n",
    "    return z\n",
    "x=graphconv(x,inputs)\n",
    "# x=Reshape([-1])(x)\n",
    "print(x.shape)\n",
    "# x=Lambda(re)(x)\n",
    "x=Flatten()(x)\n",
    "print(x.shape)\n",
    "x=Dense(4)(x)\n",
    "# print(x.shape)\n",
    "p=Dense(4,activation='softmax')(x)\n",
    "# 创建一个labels\n",
    "labels=np.array([0,1,2])\n",
    "labels=keras.utils.to_categorical(labels,num_classes=4)\n",
    "model2=Model(inputs=inputs,outputs=p)\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['acc'])\n",
    "model2.fit(nz,labels,batch_size=1,epochs=100,verbose=1)\n",
    "# x=Dense()(x)\n",
    "model2.summary()\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=Lambda(res)(x)\n",
    "# print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "A=2\n",
    "\n",
    "def iii():\n",
    "    print(A)\n",
    "iii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2],[1]])\n",
    "np.array((a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
